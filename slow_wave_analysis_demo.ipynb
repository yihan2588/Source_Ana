{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step-by-Step per-wave Calculation Demonstration (using scipy.signal.find_peaks)\n",
    "\n",
    "This notebook demonstrates the core logic of the `analyze_slow_wave` function from the EEG analysis pipeline, using `scipy.signal.find_peaks`. It processes a single slow wave CSV file step-by-step, visualizing the intermediate results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step-by-Step per-wave Calculation Demonstration (using scipy.signal.find_peaks)\n",
    "\n",
    "This notebook demonstrates the core logic of the `analyze_slow_wave` function from the EEG analysis pipeline, using `scipy.signal.find_peaks`. It processes a single slow wave CSV file step-by-step, visualizing the intermediate results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup\n",
    "\n",
    "Import necessary libraries and define helper functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "from scipy.signal import find_peaks # Import find_peaks\n",
    "\n",
    "# Define the region extraction function (copied from utils.py)\n",
    "def extract_region_name(full_name):\n",
    "    \"\"\"Extract anatomical region name from the full voxel name.\"\"\"\n",
    "    try:\n",
    "        # Simple case: 'Region.VoxelName'\n",
    "        if '.' in full_name and not \"['\" in full_name:\n",
    "            return full_name.split('.')[0]\n",
    "        # Case like \"AtlasName['Region.SubRegion'].VoxelName\" or similar\n",
    "        elif \"['\" in full_name and \".\" in full_name:\n",
    "            # Extract content within ['...']\n",
    "            content_in_brackets = full_name.split(\"['\")[1].split(\"']\")[0]\n",
    "            # Take the part before the first dot within the brackets if it exists\n",
    "            if '.' in content_in_brackets:\n",
    "                 return content_in_brackets.split('.')[0]\n",
    "            else:\n",
    "                 return content_in_brackets # Return the whole content if no dot\n",
    "        # Fallback if no known pattern matches\n",
    "        else:\n",
    "            return full_name\n",
    "    except Exception as e:\n",
    "        print(f\"Error extracting region from {full_name}: {e}\")\n",
    "        return full_name # Return original name on error\n",
    "\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "\n",
    "print(\"Libraries imported and helper function defined.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. User Input: Specify Wave Data File\n",
    "\n",
    "Enter the full path to the specific slow wave CSV file you want to analyze."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_file_path_str = input(\"Enter the path to the slow wave CSV file: \")\n",
    "csv_file_path = Path(csv_file_path_str.strip()) # Use strip() to remove leading/trailing whitespace\n",
    "\n",
    "# Basic validation\n",
    "if not csv_file_path.is_file():\n",
    "    print(f\"\\033[91mError: File not found at {csv_file_path}\\033[0m\") # Red text for error\n",
    "    # Optionally raise an error to stop execution\n",
    "    # raise FileNotFoundError(f\"File not found at {csv_file_path}\") \n",
    "else:\n",
    "    wave_name = csv_file_path.stem\n",
    "    print(f\"Processing wave: {wave_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Load and Prepare Data\n",
    "\n",
    "Read the CSV file into a pandas DataFrame. Parse the time points (converting from seconds to milliseconds) and voxel names. We also take the absolute value of the data, as the analysis focuses on the magnitude of activity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'csv_file_path' in locals() and csv_file_path.is_file():\n",
    "    try:\n",
    "        df = pd.read_csv(csv_file_path)\n",
    "        print(\"CSV loaded successfully.\")\n",
    "\n",
    "        # --- Data Parsing Logic (adapted from analyze_slow_wave) ---\n",
    "        if 'Time' in df.columns:\n",
    "            print(\"Detected format with 'Time' column.\")\n",
    "            # Format with 'Time' column first\n",
    "            numeric_cols = []\n",
    "            for col in df.columns[1:]:\n",
    "                # Ignore potential unnamed columns from index saving\n",
    "                if not str(col).startswith('Unnamed'):\n",
    "                    try:\n",
    "                        # Test if column header can be converted to float (represents time)\n",
    "                        float(col) \n",
    "                        numeric_cols.append(col)\n",
    "                    except ValueError:\n",
    "                        print(f\"  Skipping non-numeric column: {col}\")\n",
    "                        continue\n",
    "            time_points_sec = np.array([float(t) for t in numeric_cols])\n",
    "            # Select only the numeric time columns for data\n",
    "            data = df.loc[:, numeric_cols].values \n",
    "            voxel_names = df.iloc[:, 0].values\n",
    "        else:\n",
    "             # Try inferring format without 'Time' column\n",
    "             print(\"Attempting to infer format without 'Time' column.\")\n",
    "             # Assume first column is voxel names, rest are time points\n",
    "             numeric_cols = []\n",
    "             for col in df.columns[1:]:\n",
    "                 if not str(col).startswith('Unnamed'):\n",
    "                     try:\n",
    "                         float(col)\n",
    "                         numeric_cols.append(col)\n",
    "                     except ValueError:\n",
    "                         print(f\"  Skipping non-numeric column: {col}\")\n",
    "                         continue\n",
    "             if not numeric_cols:\n",
    "                 raise ValueError(\"Could not find numeric time columns after the first column.\")\n",
    "             \n",
    "             time_points_sec = np.array([float(t) for t in numeric_cols])\n",
    "             data = df.loc[:, numeric_cols].values\n",
    "             voxel_names = df.iloc[:, 0].values\n",
    "             print(\"Assumed first column is voxel name, subsequent numeric columns are time.\")\n",
    "\n",
    "        # Convert time to milliseconds and take absolute value of data\n",
    "        time_points_ms = time_points_sec * 1000 \n",
    "        abs_data = np.abs(data) \n",
    "\n",
    "        print(f\"\\nData shape: {data.shape} (voxels, time points)\")\n",
    "        print(f\"Time points range (ms): {time_points_ms.min():.1f} to {time_points_ms.max():.1f}\")\n",
    "        print(f\"Number of voxels: {len(voxel_names)}\")\n",
    "\n",
    "        # --- Visualization: Raw Data Snippet ---\n",
    "        print(\"\\nRaw Data Head:\")\n",
    "        display(df.head())\n",
    "\n",
    "        # --- Visualization: Sample Waveforms (Absolute Values) ---\n",
    "        num_voxels_to_plot = min(5, abs_data.shape[0]) # Plot up to 5 voxels\n",
    "        plt.figure(figsize=(12, 4))\n",
    "        for i in range(num_voxels_to_plot):\n",
    "            plt.plot(time_points_ms, abs_data[i, :], label=f'Voxel {i}: {voxel_names[i]}')\n",
    "        \n",
    "        plt.title(f'Sample Voxel Waveforms (Absolute Value) - Wave: {wave_name}')\n",
    "        plt.xlabel('Time (ms)')\n",
    "        plt.ylabel('Absolute Signal Value')\n",
    "        plt.legend(loc='upper right', fontsize='small')\n",
    "        plt.grid(True)\n",
    "        plt.show()\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"\\033[91mError loading or parsing CSV: {e}\\033[0m\")\n",
    "        # Clear potentially partially defined variables\n",
    "        if 'df' in locals(): del df\n",
    "        if 'data' in locals(): del data\n",
    "        if 'abs_data' in locals(): del abs_data\n",
    "        if 'time_points_ms' in locals(): del time_points_ms\n",
    "        if 'voxel_names' in locals(): del voxel_names\n",
    "else:\n",
    "    print(\"\\033[91mCannot proceed: CSV file path is not valid or file not found.\\033[0m\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Apply Time Window\n",
    "\n",
    "Select the data only within the specified time window (-50ms to +50ms). This focuses the analysis on the core part of the slow wave."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'time_points_ms' in locals() and 'abs_data' in locals():\n",
    "    window_start_ms = -50\n",
    "    window_end_ms = 50\n",
    "    window_mask = (time_points_ms >= window_start_ms) & (time_points_ms <= window_end_ms)\n",
    "\n",
    "    if sum(window_mask) == 0:\n",
    "        print(f\"\\033[93mWarning: No time points found in window [{window_start_ms}, {window_end_ms}] ms. Using full time range as fallback.\\033[0m\")\n",
    "        window_mask = np.ones_like(time_points_ms, dtype=bool) # Fallback to using all points\n",
    "\n",
    "    # Apply the mask to data and time points\n",
    "    windowed_data = abs_data[:, window_mask]\n",
    "    windowed_times_ms = time_points_ms[window_mask]\n",
    "\n",
    "    print(f\"Windowed data shape: {windowed_data.shape} (voxels, time points in window)\")\n",
    "    if windowed_times_ms.size > 0:\n",
    "        print(f\"Windowed time points range (ms): {windowed_times_ms.min():.1f} to {windowed_times_ms.max():.1f}\")\n",
    "    else:\n",
    "        print(\"Windowed time points: None (empty window)\")\n",
    "\n",
    "    # --- Visualization: Windowed Waveforms ---\n",
    "    plt.figure(figsize=(12, 4))\n",
    "    num_voxels_to_plot = min(5, windowed_data.shape[0])\n",
    "    for i in range(num_voxels_to_plot):\n",
    "        plt.plot(windowed_times_ms, windowed_data[i, :], label=f'Voxel {i}: {voxel_names[i]}')\n",
    "    \n",
    "    plt.title(f'Sample Waveforms within Window [{window_start_ms}ms, {window_end_ms}ms]')\n",
    "    plt.xlabel('Time (ms)')\n",
    "    plt.ylabel('Absolute Signal Value')\n",
    "    plt.legend(loc='upper right', fontsize='small')\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"\\033[91mCannot proceed: Required variables ('time_points_ms', 'abs_data') not defined from previous step.\\033[0m\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Calculate Threshold\n",
    "\n",
    "Determine the activity threshold. This is calculated dynamically as a percentage (default 25%) of the maximum absolute signal value found across *all* voxels within the time window."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'windowed_data' in locals():\n",
    "    threshold_percent = 25\n",
    "    \n",
    "    if windowed_data.size > 0:\n",
    "        max_current_in_window = np.max(windowed_data)\n",
    "        threshold = max_current_in_window * (threshold_percent / 100.0)\n",
    "    else:\n",
    "        max_current_in_window = 0\n",
    "        threshold = 0\n",
    "        print(\"\\033[93mWarning: Windowed data is empty, threshold set to 0.\\033[0m\")\n",
    "\n",
    "    # Use scientific notation for potentially very small numbers\n",
    "    print(f\"Max absolute value in window [{window_start_ms}ms, {window_end_ms}ms]: {max_current_in_window:.6e}\")\n",
    "    print(f\"Calculated threshold ({threshold_percent}%): {threshold:.10e}\")\n",
    "\n",
    "    # --- Visualization: Threshold on Sample Waveform ---\n",
    "    if windowed_data.size > 0:\n",
    "        plt.figure(figsize=(12, 4))\n",
    "        # Plot the first voxel's windowed data as an example\n",
    "        voxel_to_plot_idx = 0\n",
    "        plt.plot(windowed_times_ms, windowed_data[voxel_to_plot_idx, :], label=f'Voxel {voxel_to_plot_idx}: {voxel_names[voxel_to_plot_idx]}')\n",
    "        # Draw the threshold line\n",
    "        plt.axhline(threshold, color='r', linestyle='--', label=f'Threshold ({threshold:.10e})')\n",
    "        \n",
    "        plt.title(f'Sample Windowed Waveform with Threshold')\n",
    "        plt.xlabel('Time (ms)')\n",
    "        plt.ylabel('Absolute Signal Value')\n",
    "        plt.legend(loc='upper right')\n",
    "        plt.grid(True)\n",
    "        plt.show()\n",
    "    else:\n",
    "        print(\"Cannot visualize threshold: Windowed data is empty.\")\n",
    "else:\n",
    "    print(\"\\033[91mCannot proceed: Required variable ('windowed_data') not defined from previous step.\\033[0m\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Detect Peaks and Voxel Involvement (using scipy.signal.find_peaks)\n",
    "\n",
    "For each voxel:\n",
    "1. Use `scipy.signal.find_peaks` to find all peaks within the time window that are **above** the calculated `threshold`.\n",
    "2. If peaks above the threshold exist, find the one that occurs earliest in time.\n",
    "3. A voxel is considered \"involved\" if it has at least one peak above the threshold within the window. The time of the *first* such peak is recorded.\n",
    "\n",
    "Finally, calculate the total number and percentage of involved voxels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'windowed_data' in locals() and 'threshold' in locals():\n",
    "    voxel_peak_times = [] # Stores info for involved voxels\n",
    "    involved_voxels_indices = []\n",
    "    example_involved_indices = [] # Store indices for visualization\n",
    "    example_uninvolved_indices = []\n",
    "    involved_peak_info = {} # Store peak info for involved examples\n",
    "\n",
    "    # Iterate through each voxel\n",
    "    for voxel_idx in range(windowed_data.shape[0]):\n",
    "        voxel_data = windowed_data[voxel_idx]\n",
    "        peaks_above_threshold = [] # Store (time, value) tuples for this voxel\n",
    "\n",
    "        # Use scipy.signal.find_peaks with the height parameter\n",
    "        peak_indices, _ = find_peaks(voxel_data, height=threshold)\n",
    "        \n",
    "        if peak_indices.size > 0:\n",
    "            # Get the times and values for the found peaks\n",
    "            peak_times = windowed_times_ms[peak_indices]\n",
    "            peak_values = voxel_data[peak_indices]\n",
    "            peaks_above_threshold = list(zip(peak_times, peak_values))\n",
    "        \n",
    "        # If any peaks were found above the threshold for this voxel\n",
    "        if peaks_above_threshold:\n",
    "            # Find the peak that occurred earliest in time\n",
    "            first_peak = min(peaks_above_threshold, key=lambda x: x[0])\n",
    "            first_peak_time_ms = first_peak[0]\n",
    "            first_peak_value = first_peak[1]\n",
    "            \n",
    "            # Record voxel info\n",
    "            voxel_peak_times.append({\n",
    "                'voxel_index': voxel_idx,\n",
    "                'full_name': voxel_names[voxel_idx],\n",
    "                'peak_time_ms': first_peak_time_ms\n",
    "                # Optionally add 'peak_value': first_peak_value\n",
    "            })\n",
    "            involved_voxels_indices.append(voxel_idx)\n",
    "            \n",
    "            # Store info for the first two involved voxels found (for visualization)\n",
    "            if len(example_involved_indices) < 2:\n",
    "                example_involved_indices.append(voxel_idx)\n",
    "                involved_peak_info[voxel_idx] = {'time': first_peak_time_ms, 'value': first_peak_value}\n",
    "        else:\n",
    "             # Store index of the first two uninvolved voxels found (for visualization)\n",
    "             if len(example_uninvolved_indices) < 2:\n",
    "                 example_uninvolved_indices.append(voxel_idx)\n",
    "\n",
    "    # --- Calculate Involvement Statistics ---\n",
    "    total_voxels = abs_data.shape[0]\n",
    "    involvement_count = len(involved_voxels_indices)\n",
    "    involvement_percentage = (involvement_count / total_voxels) * 100 if total_voxels > 0 else 0\n",
    "\n",
    "    print(f\"Total voxels: {total_voxels}\")\n",
    "    print(f\"Involved voxels (peak > threshold in window): {involvement_count}\")\n",
    "    print(f\"Involvement Percentage: {involvement_percentage:.2f}%\")\n",
    "\n",
    "    # Create DataFrame for easier handling of involved voxels\n",
    "    involved_voxels_df = pd.DataFrame(voxel_peak_times)\n",
    "    if not involved_voxels_df.empty:\n",
    "        print(\"\\nFirst few involved voxels and their first peak times:\")\n",
    "        display(involved_voxels_df.head())\n",
    "    else:\n",
    "        print(\"\\nNo voxels were involved in this wave.\")\n",
    "\n",
    "    # --- Visualization: Involved vs. Uninvolved Examples (2 each) ---\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 10), sharey=True)\n",
    "    fig.suptitle('Example Voxel Involvement (using find_peaks)')\n",
    "\n",
    "    # Plot involved examples\n",
    "    for i, idx in enumerate(example_involved_indices):\n",
    "        ax = axes[0, i]\n",
    "        ax.plot(windowed_times_ms, windowed_data[idx, :], label=f'Voxel {idx}')\n",
    "        ax.axhline(threshold, color='r', linestyle='--', label=f'Threshold ({threshold:.6e})')\n",
    "        peak_info = involved_peak_info[idx]\n",
    "        ax.plot(peak_info['time'], peak_info['value'], 'ro', markersize=8, label='First Peak > Threshold')\n",
    "        ax.set_title(f'Involved Voxel Example {i+1} (Idx: {idx})')\n",
    "        ax.set_xlabel('Time (ms)')\n",
    "        if i == 0:\n",
    "            ax.set_ylabel('Absolute Signal Value')\n",
    "        ax.legend()\n",
    "        ax.grid(True)\n",
    "    # Fill remaining involved plots if fewer than 2 found\n",
    "    for i in range(len(example_involved_indices), 2):\n",
    "        axes[0, i].set_title(f'Involved Voxel Example {i+1} (N/A)')\n",
    "        axes[0, i].text(0.5, 0.5, 'Less than 2 involved voxels found', ha='center', va='center', transform=axes[0, i].transAxes)\n",
    "        axes[0, i].set_xlabel('Time (ms)')\n",
    "\n",
    "    # Plot uninvolved examples\n",
    "    for i, idx in enumerate(example_uninvolved_indices):\n",
    "        ax = axes[1, i]\n",
    "        ax.plot(windowed_times_ms, windowed_data[idx, :], label=f'Voxel {idx}')\n",
    "        ax.axhline(threshold, color='r', linestyle='--', label=f'Threshold ({threshold:.6e})')\n",
    "        ax.set_title(f'Uninvolved Voxel Example {i+1} (Idx: {idx})')\n",
    "        ax.set_xlabel('Time (ms)')\n",
    "        if i == 0:\n",
    "            ax.set_ylabel('Absolute Signal Value')\n",
    "        ax.legend()\n",
    "        ax.grid(True)\n",
    "    # Fill remaining uninvolved plots if fewer than 2 found\n",
    "    for i in range(len(example_uninvolved_indices), 2):\n",
    "        axes[1, i].set_title(f'Uninvolved Voxel Example {i+1} (N/A)')\n",
    "        axes[1, i].text(0.5, 0.5, 'Less than 2 uninvolved voxels found', ha='center', va='center', transform=axes[1, i].transAxes)\n",
    "        axes[1, i].set_xlabel('Time (ms)')\n",
    "\n",
    "    plt.tight_layout(rect=[0, 0.03, 1, 0.95]) # Adjust layout to prevent title overlap\n",
    "    plt.show()\n",
    "\n",
    "    # --- Visualization: Involvement Bar Chart ---\n",
    "    plt.figure(figsize=(4, 3))\n",
    "    labels = ['Involved', 'Uninvolved']\n",
    "    counts = [involvement_count, total_voxels - involvement_count]\n",
    "    plt.bar(labels, counts, color=['skyblue', 'lightgray'])\n",
    "    plt.title('Voxel Involvement Count')\n",
    "    plt.ylabel('Number of Voxels')\n",
    "    for i, count in enumerate(counts):\n",
    "        plt.text(i, count + 0.01 * total_voxels, str(count), ha='center') # Add counts on bars\n",
    "    plt.show()\n",
    "\n",
    "else:\n",
    "    print(\"\\033[91mCannot proceed: Required variables ('windowed_data', 'threshold') not defined from previous step.\\033[0m\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Map Voxels to Regions\n",
    "\n",
    "Use the `extract_region_name` helper function to simplify the detailed voxel names (e.g., `Frontal_Sup_L.Source001`) to their corresponding anatomical region names (e.g., `Frontal_Sup_L`) for all *involved* voxels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'involved_voxels_df' in locals() and not involved_voxels_df.empty:\n",
    "    # Apply the function to the 'full_name' column to create a new 'region' column\n",
    "    involved_voxels_df['region'] = involved_voxels_df['full_name'].apply(extract_region_name)\n",
    "    print(\"\\nInvolved voxels DataFrame with extracted regions:\")\n",
    "    display(involved_voxels_df.head())\n",
    "elif 'involved_voxels_df' in locals():\n",
    "     print(\"\\nNo involved voxels to map to regions.\")\n",
    "else:\n",
    "    print(\"\\033[91mCannot proceed: Required variable ('involved_voxels_df') not defined from previous step.\\033[0m\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Identify Origin Regions\n",
    "\n",
    "The \"origins\" of the slow wave are defined as the set of regions corresponding to the involved voxels that showed the earliest activity (i.e., had the earliest first peak time above threshold).\n",
    "\n",
    "1. Sort the involved voxels by their `peak_time_ms`.\n",
    "2. Select the top 10% of these sorted voxels (with a minimum of 1 voxel).\n",
    "3. The unique regions associated with these earliest voxels are considered the origin regions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize origins_df to None or empty DataFrame\n",
    "origins_df = pd.DataFrame()\n",
    "origin_regions = []\n",
    "\n",
    "if 'involved_voxels_df' in locals() and not involved_voxels_df.empty:\n",
    "    # Sort involved voxels by peak time\n",
    "    sorted_involved_df = involved_voxels_df.sort_values('peak_time_ms')\n",
    "\n",
    "    # Determine the number of origins (earliest 10%, minimum 1)\n",
    "    n_origins = max(1, int(len(sorted_involved_df) * 0.1))\n",
    "\n",
    "    # Select the earliest voxels as origins\n",
    "    origins_df = sorted_involved_df.head(n_origins).copy() # Use .copy() to avoid SettingWithCopyWarning\n",
    "\n",
    "    print(f\"\\nIdentifying origins (earliest {n_origins} involved voxels based on peak time):\")\n",
    "    display(origins_df[['full_name', 'region', 'peak_time_ms']])\n",
    "\n",
    "    # Get the unique regions from the origins DataFrame\n",
    "    origin_regions = sorted(list(origins_df['region'].unique()))\n",
    "    print(f\"\\nUnique Origin Regions ({len(origin_regions)}): {origin_regions}\")\n",
    "    \n",
    "    # --- Visualization: Peak Time Distribution ---\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    plt.hist(involved_voxels_df['peak_time_ms'], bins=20, color='skyblue', edgecolor='black')\n",
    "    plt.title('Distribution of First Peak Times for Involved Voxels')\n",
    "    plt.xlabel('Peak Time (ms)')\n",
    "    plt.ylabel('Number of Voxels')\n",
    "    \n",
    "    # Add a vertical line indicating the cutoff for origins\n",
    "    if not origins_df.empty:\n",
    "        cutoff_time = origins_df['peak_time_ms'].max()\n",
    "        plt.axvline(cutoff_time, color='r', linestyle='--', label=f'Origin Cutoff ({cutoff_time:.1f} ms)')\n",
    "        plt.legend()\n",
    "        \n",
    "    plt.grid(axis='y', alpha=0.5)\n",
    "    plt.show()\n",
    "\n",
    "elif 'involved_voxels_df' in locals():\n",
    "     print(\"\\nNo involved voxels, cannot identify origins.\")\n",
    "else:\n",
    "    print(\"\\033[91mCannot proceed: Required variable ('involved_voxels_df') not defined from previous step.\\033[0m\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Summary of Results\n",
    "\n",
    "Display the key metrics calculated for this specific wave."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*30)\n",
    "print(f\"   Summary for Wave: {wave_name}\")\n",
    "print(\"=\"*30)\n",
    "\n",
    "# Check if variables exist before printing\n",
    "if 'involvement_percentage' in locals() and 'involvement_count' in locals() and 'total_voxels' in locals():\n",
    "    print(f\"- Involvement:      {involvement_percentage:.2f}% ({involvement_count} / {total_voxels} voxels)\")\n",
    "else:\n",
    "    print(\"- Involvement:      Not calculated (error in previous steps)\")\n",
    "\n",
    "if 'origin_regions' in locals():\n",
    "    if origin_regions: # Check if the list is not empty\n",
    "        print(f\"- Origin Regions:   {len(origin_regions)} unique regions\")\n",
    "        # Optionally print the list, wrap if long\n",
    "        regions_str = ', '.join(origin_regions)\n",
    "        max_len = 70\n",
    "        if len(regions_str) > max_len:\n",
    "             print(f\"                    {regions_str[:max_len]}...\")\n",
    "        else:\n",
    "             print(f\"                    {regions_str}\")\n",
    "        # Display origin details DataFrame again if needed\n",
    "        # print(\"\\nOrigin Voxel Details:\")\n",
    "        # display(origins_df[['region', 'peak_time_ms']])\n",
    "    else:\n",
    "        # Handle case where involved_voxels_df existed but was empty, or origins_df ended up empty\n",
    "        if 'involved_voxels_df' in locals() and involved_voxels_df.empty:\n",
    "             print(\"- Origin Regions:   None (no involved voxels)\")\n",
    "        else:\n",
    "             print(\"- Origin Regions:   None (involved voxels found, but origin calculation might have yielded none - check logic or data)\")\n",
    "else:\n",
    "    print(\"- Origin Regions:   Not calculated (error in previous steps)\")\n",
    "\n",
    "if 'window_start_ms' in locals() and 'window_end_ms' in locals():\n",
    "    print(f\"- Analysis Window:  {window_start_ms}ms to {window_end_ms}ms\")\n",
    "else:\n",
    "    print(\"- Analysis Window:  Not set (error in previous steps)\")\n",
    "\n",
    "if 'threshold' in locals():\n",
    "    print(f\"- Threshold Value:  {threshold:.10e}\")\n",
    "else:\n",
    "    print(\"- Threshold Value:  Not calculated (error in previous steps)\")\n",
    "\n",
    "print(\"=\"*30)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
